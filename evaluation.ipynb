{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types d'évaluation chargés:\n",
      "• 'couleur' - Nombre des images: 4\n",
      "• 'font' - Nombre des images: 3\n",
      "• 'https' - Nombre des images: 4\n",
      "• 'manuscript' - Nombre des images: 1\n",
      "• 'rotation' - Nombre des images: 3\n",
      "• 'screenshot' - Nombre des images: 5\n",
      "Total de vrai objets: 71\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "#DOSSIER_EVALUATION = \"test/\"\n",
    "DOSSIER_EVALUATION = \"difficulties/\"\n",
    "FICHIER_NOMS_CLASS = DOSSIER_EVALUATION + \"classes.txt\"\n",
    "\n",
    "# lire les class dans classes.txt\n",
    "classes = []\n",
    "fichier_noms_class = open(FICHIER_NOMS_CLASS, \"r\")\n",
    "while True:\n",
    "     line = fichier_noms_class.readline()\n",
    "     if not line: \n",
    "          break\n",
    "     classes.append(line.strip()) # lire sans '\\n'\n",
    "\n",
    "g_vrai_objets_total = 0\n",
    "\n",
    "types_evaluations = []\n",
    "img_buffer = []\n",
    "img_annotation = []\n",
    "evaluations_nombre_vrai_objet = [] # contient nombre de vrai objet pour chaque evaluation\n",
    "\n",
    "# format de nom d'image: <type>_<nombre>.png/jpg/jpeg\n",
    "# check image a un fichier d'annotation \".txt\" sur la format YOLO\n",
    "for fichier in os.listdir(DOSSIER_EVALUATION):\n",
    "     \n",
    "     # n'autoriser que les images\n",
    "     string_couper = fichier.split('.') \n",
    "     extension = string_couper[1]\n",
    "     if extension != \"png\" and extension != \"jpg\" and extension != \"jpeg\" and extension != \"bmp\": \n",
    "          continue\n",
    "     \n",
    "     # vérifier le type d'évaluation, ajouter si n'existe pas\n",
    "     current_evaluation_index = -1\n",
    "     nom_evaluation = string_couper[0].split('_')[0]\n",
    "     evaluation_trouver = False\n",
    "     for type_index, type in enumerate(types_evaluations):\n",
    "          current_evaluation_index = type_index\n",
    "          if(type == nom_evaluation):\n",
    "               evaluation_trouver = True\n",
    "               break\n",
    "\n",
    "     if not evaluation_trouver:\n",
    "          types_evaluations.append(nom_evaluation)\n",
    "          img_buffer.append([])\n",
    "          img_annotation.append([])\n",
    "          evaluations_nombre_vrai_objet.append(0)\n",
    "          current_evaluation_index += 1\n",
    "     \n",
    "     # lire l'image\n",
    "     #img_buffer[current_evaluation_index].append([])\n",
    "     img = cv2.imread(DOSSIER_EVALUATION + fichier)\n",
    "     hauteur, largeur,_ = img.shape\n",
    "     img_buffer[current_evaluation_index].append(img)\n",
    "     \n",
    "     \n",
    "     # lire le fichier d'annotation \n",
    "     img_annotation[current_evaluation_index].append([])\n",
    "     fichier_annotation = open(DOSSIER_EVALUATION + string_couper[0] + \".txt\", \"r\")\n",
    "     while True:\n",
    "          line = fichier_annotation.readline().strip()\n",
    "          if not line:\n",
    "               break\n",
    "          # decoder YOLO format\n",
    "          data = line.split(' ')\n",
    "          data[0] = int(data[0])\n",
    "          data[1] = float(data[1]) * largeur\n",
    "          data[2] = float(data[2]) * hauteur\n",
    "          data[3] = float(data[3]) * largeur \n",
    "          data[4] = float(data[4]) * hauteur\n",
    "\n",
    "          # faire le point en haut à gauche au lieu du centre\n",
    "          data[1] -= data[3] / 2\n",
    "          data[2] -= data[4] / 2\n",
    "\n",
    "          img_annotation[current_evaluation_index][-1].append(data)\n",
    "          evaluations_nombre_vrai_objet[current_evaluation_index] += 1\n",
    "          g_vrai_objets_total += 1\n",
    "\n",
    "# résumé des données de test\n",
    "print(\"Types d'évaluation chargés:\")\n",
    "for id, evaluation in enumerate(types_evaluations):\n",
    "     print(\"• '\" + evaluation + \"' - Nombre des images: \" + str(len(img_annotation[id])))\n",
    "\n",
    "print(\"Total de vrai objets: \" + str(g_vrai_objets_total))\n",
    "\n",
    "# Fonctions utilitaires\n",
    "def IntersectionSurUnion(x1, y1, largeur1, hauteur1, \\\n",
    "                         x2, y2, largeur2, hauteur2):\n",
    "\n",
    "     x1_droit = x1 + largeur1\n",
    "     y1_droit = y1 + hauteur1\n",
    "\n",
    "     x2_droit = x2 + largeur2\n",
    "     y2_droit = y2 + hauteur2\n",
    "\n",
    "     dx = min(x1_droit, x2_droit) - max(x1, x2)\n",
    "     dy = min(y1_droit, y2_droit) - max(y1, y2)\n",
    "\n",
    "     # vérifier s'ils se croisent\n",
    "     if dx <= 0 or dy <= 0:\n",
    "          return 0\n",
    "\n",
    "     # surface de chevauchement\n",
    "     surface_chevauchement = dx * dy\n",
    "\n",
    "     # surface d'union\n",
    "     surface_union = ( (largeur1 * hauteur1) + (largeur2 * hauteur2) - surface_chevauchement )\n",
    "\n",
    "     return surface_chevauchement / surface_union\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP: IoU >= THR\n",
    "# FP: IoU < THR && Incorrect detection\n",
    "# Précision : TP / (TP + FP) = TP / Tous les prediction\n",
    "# Rappel: TP / (TP + FN) = TP / Tous les vrai objets\n",
    "# Tous les prediction: retourné par le model\n",
    "# Tous les vrai objets: nombre des annotation dans un image\n",
    "# Il rest TP utilisant le seuillage ou IoU >= SEUIL\n",
    "\n",
    "IOU_SEUIL = 0.5\n",
    "\n",
    "# Précision x Rappel courbe\n",
    "CONF_SEUIL_MAX = 0.8\n",
    "CONF_SEUIL_MIN = 0\n",
    "CONF_NOMBRE_PAS = 11\n",
    "CONF_PAS = (CONF_SEUIL_MAX -  CONF_SEUIL_MIN) / CONF_NOMBRE_PAS\n",
    "\n",
    "ECRIRE_IMG_CONF_SEIL = 0.5\n",
    "\n",
    "# Précision moyenne utilisant une interpolation de 11 points\n",
    "def PrecisionMoyenne(list_rappels, list_precision):\n",
    "     somme = 0\n",
    "\n",
    "     point = 0\n",
    "     while point <= 1:\n",
    "          max = 0\n",
    "          for id_rappel, rappel in enumerate(list_rappels):\n",
    "               precision = list_precision[id_rappel]\n",
    "               if rappel > point and precision > max:\n",
    "                    max = precision\n",
    "          somme += max\n",
    "          point += 0.1\n",
    "\n",
    "     return somme / 11\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def DessinerCourbePrecisionRappel(list_rappels, list_precisions, nom_evaluation, iou_seuil, dossier_sortie):\n",
    "     list_rappels.append(1)\n",
    "     list_precisions.append(0)\n",
    "\n",
    "     precision_moyenne = (PrecisionMoyenne(list_rappels, list_precisions)) * 100\n",
    "     precision_moyenne = round(precision_moyenne, 2)\n",
    "\n",
    "     fig, ax = plt.subplots()\n",
    "     ax.plot(list_rappels, list_precisions, color=\"blue\")\n",
    "\n",
    "     ax.set_title(\"Courbe Précision-Rappel - \" + nom_evaluation + \" - IOU:\" + str(iou_seuil) + \"\\n Précision Moyenne (AP): \" + str(precision_moyenne) + \"%\" )\n",
    "     ax.set_ylabel(\"Précision\")\n",
    "     ax.set_xlabel(\"Rappel\")\n",
    "\n",
    "     plt.savefig( dossier_sortie + \"pr_\" + nom_evaluation + \".png\", dpi=800)\n",
    "     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-1-31 Python-3.9.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.8\n",
      "• 'couleur' => Précision: 1.0 - Rappel: 0.06666666666666667\n",
      "• 'font' => Précision: 1.0 - Rappel: 0.75\n",
      "• 'https' => Précision: 0 - Rappel: 0.0\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 0 - Rappel: 0.0\n",
      "• 'screenshot' => Précision: 0 - Rappel: 0.0\n",
      "# Global => Précision: 0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.7272727272727273\n",
      "• 'couleur' => Précision: 0.6666666666666666 - Rappel: 0.13333333333333333\n",
      "• 'font' => Précision: 1.0 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 1.0 - Rappel: 0.0625\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0 - Rappel: 0.0\n",
      "# Global => Précision: 0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.6545454545454545\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 1.0 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 1.0 - Rappel: 0.0625\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0 - Rappel: 0.0\n",
      "# Global => Précision: 0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.5818181818181818\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.9090909090909091 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 0.3333333333333333 - Rappel: 0.0625\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0 - Rappel: 0.0\n",
      "# Global => Précision: 0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.509090909090909\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.8333333333333334 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 0.5 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0.0 - Rappel: 0.0\n",
      "# Global => Précision: 0.0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.4363636363636363\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.7692307692307693 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 0.4 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0.0 - Rappel: 0.0\n",
      "# Global => Précision: 0.0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.36363636363636354\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.7142857142857143 - Rappel: 0.8333333333333334\n",
      "• 'https' => Précision: 0.4 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0.0 - Rappel: 0.0\n",
      "# Global => Précision: 0.0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.2909090909090908\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.6875 - Rappel: 0.9166666666666666\n",
      "• 'https' => Précision: 0.2857142857142857 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0.0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.08333333333333333\n",
      "• 'screenshot' => Précision: 0.0 - Rappel: 0.0\n",
      "# Global => Précision: 0.0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.21818181818181803\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.6111111111111112 - Rappel: 0.9166666666666666\n",
      "• 'https' => Précision: 0.25 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0.0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.16666666666666666\n",
      "• 'screenshot' => Précision: 0.0 - Rappel: 0.0\n",
      "# Global => Précision: 0.0 - Rappel: 0.0\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.14545454545454528\n",
      "• 'couleur' => Précision: 0.75 - Rappel: 0.2\n",
      "• 'font' => Précision: 0.5789473684210527 - Rappel: 0.9166666666666666\n",
      "• 'https' => Précision: 0.18181818181818182 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0.0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.16666666666666666\n",
      "• 'screenshot' => Précision: 0.16666666666666666 - Rappel: 0.1111111111111111\n",
      "# Global => Précision: 0.16666666666666666 - Rappel: 0.1111111111111111\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.07272727272727254\n",
      "• 'couleur' => Précision: 0.625 - Rappel: 0.3333333333333333\n",
      "• 'font' => Précision: 0.4782608695652174 - Rappel: 0.9166666666666666\n",
      "• 'https' => Précision: 0.13333333333333333 - Rappel: 0.125\n",
      "• 'manuscript' => Précision: 0.0 - Rappel: 0.0\n",
      "• 'rotation' => Précision: 1.0 - Rappel: 0.16666666666666666\n",
      "• 'screenshot' => Précision: 0.14285714285714285 - Rappel: 0.1111111111111111\n",
      "# Global => Précision: 0.14285714285714285 - Rappel: 0.1111111111111111\n",
      "Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\n"
     ]
    }
   ],
   "source": [
    "# YOLOv5\n",
    "import torch\n",
    "\n",
    "DIMENSIONS_ENTREE = 640\n",
    "\n",
    "DOSSIER_SORTIE = \"predictions/yolov5/\"\n",
    "FICHIER_POIDS = \"weights/yolov5_best.pt\"\n",
    "\n",
    "yolov5 = torch.hub.load('ultralytics/yolov5', 'custom', path=FICHIER_POIDS)\n",
    "\n",
    "global_pr_courbe = [ [], []] # courbe global de model \n",
    "evaluations_pr_courbes = [] # liste des courbe pour chaque evaluation \n",
    "for eve_id in range(len(types_evaluations)):\n",
    "     evaluations_pr_courbes.append([[],[]])\n",
    "\n",
    "conf_seuil_current = CONF_SEUIL_MAX\n",
    "while conf_seuil_current >= CONF_SEUIL_MIN:\n",
    "     print(\"\\nPour Seuils: IoU: \" + str(IOU_SEUIL) + \" - Confedence: \" + str(conf_seuil_current) )\n",
    "     yolov5.conf = conf_seuil_current\n",
    "     conf_seuil_current -= CONF_PAS\n",
    "\n",
    "     g_tp = 0\n",
    "     g_prediction_total = 0\n",
    "\n",
    "     for eve_id, evaluation in enumerate(types_evaluations):\n",
    "          eve_tp = 0\n",
    "          eve_prediction_total = 0\n",
    "          eve_vrai_objets = evaluations_nombre_vrai_objet[eve_id]\n",
    "\n",
    "          # prepare l'image: RGB, 640x640\n",
    "          for img_id, img in enumerate(img_buffer[eve_id]):\n",
    "               input = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "               input = cv2.resize(input, (DIMENSIONS_ENTREE, DIMENSIONS_ENTREE), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "               prediction = yolov5([input])\n",
    "               detections = prediction.xyxy[0].detach().cpu().numpy()\n",
    "\n",
    "               hauteur, largeur,_ = img.shape\n",
    "               echelle_largeur = DIMENSIONS_ENTREE / largeur \n",
    "               echelle_hateur = DIMENSIONS_ENTREE / hauteur\n",
    "\n",
    "               # d: [ xmin, ymin, xmax, ymax, confd, class ]\n",
    "               for d in detections:\n",
    "                    g_prediction_total += 1\n",
    "                    eve_prediction_total += 1\n",
    "\n",
    "                    # a: [ class, xmin, ymin, largeur, hatueur ]\n",
    "                    for a in img_annotation[eve_id][img_id]:\n",
    "                         detection_largeur = d[2] - d[0]\n",
    "                         detection_hateur = d[3] - d[1]\n",
    "\n",
    "                         # dimension à l'échelle 640x640\n",
    "                         vrai_x = a[1] * echelle_largeur\n",
    "                         vrai_y = a[2] * echelle_hateur\n",
    "                         vrai_largeur = a[3] * echelle_largeur\n",
    "                         vrai_hauteur = a[4] * echelle_hateur\n",
    "\n",
    "                         iou_score = IntersectionSurUnion(d[0], d[1], detection_largeur, detection_hateur, \n",
    "                                                            vrai_x, vrai_y, vrai_largeur, vrai_hauteur)\n",
    "     \n",
    "                         # IoU >= seuil et class correct\n",
    "                         if iou_score >= IOU_SEUIL and d[5] == a[0]:\n",
    "                              g_tp += 1\n",
    "                              eve_tp += 1\n",
    "\n",
    "               # Dessinez des boîtes, basculez les canaux de couleur vers BGR puis écrivez sur le disque\n",
    "               if conf_seuil_current >= ECRIRE_IMG_CONF_SEIL:\n",
    "                    result = prediction.render()[0]\n",
    "                    result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(DOSSIER_SORTIE + types_evaluations[eve_id] + \"_\" + str(img_id) + \".PNG\", result)\n",
    "\n",
    "          # Calculate Precision et rappel pour l'evaluation current\n",
    "          eve_precision = (eve_tp / eve_prediction_total) if eve_prediction_total != 0 else 0\n",
    "          eve_rappel =  eve_tp / eve_vrai_objets\n",
    "\n",
    "          evaluations_pr_courbes[eve_id][0].append(eve_rappel)\n",
    "          evaluations_pr_courbes[eve_id][1].append(eve_precision)\n",
    "\n",
    "          print(\"• '\" + types_evaluations[eve_id] + \"' => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "\n",
    "     # Global\n",
    "     g_precision = (g_tp / g_prediction_total) if g_prediction_total != 0 else 0\n",
    "     g_rappel =  g_tp / g_vrai_objets_total\n",
    "\n",
    "     global_pr_courbe[0].append(g_rappel)\n",
    "     global_pr_courbe[1].append(g_precision)\n",
    "\n",
    "     print(\"# Global => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "\n",
    "\n",
    "# Courbe global\n",
    "print(\"Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\")\n",
    "DessinerCourbePrecisionRappel(global_pr_courbe[0], global_pr_courbe[1], \"Global\", IOU_SEUIL, DOSSIER_SORTIE)\n",
    "\n",
    "# Courbe pour chaque type d'evaluation\n",
    "for eve_id, nom_eve in enumerate(types_evaluations):\n",
    "     DessinerCourbePrecisionRappel( evaluations_pr_courbes[eve_id][0], evaluations_pr_courbes[eve_id][1], nom_eve, IOU_SEUIL, DOSSIER_SORTIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.8\n",
      "• 'vrai' => Précision: 1.0 - Rappel: 0.8971428571428571\n",
      "# Global => Précision: 1.0 - Rappel: 0.8971428571428571\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.7272727272727273\n",
      "• 'vrai' => Précision: 1.0 - Rappel: 0.9314285714285714\n",
      "# Global => Précision: 1.0 - Rappel: 0.9314285714285714\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.6545454545454545\n",
      "• 'vrai' => Précision: 1.0 - Rappel: 0.9485714285714286\n",
      "# Global => Précision: 1.0 - Rappel: 0.9485714285714286\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.5818181818181818\n",
      "• 'vrai' => Précision: 1.0 - Rappel: 0.9485714285714286\n",
      "# Global => Précision: 1.0 - Rappel: 0.9485714285714286\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.509090909090909\n",
      "• 'vrai' => Précision: 1.0 - Rappel: 0.9714285714285714\n",
      "# Global => Précision: 1.0 - Rappel: 0.9714285714285714\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.4363636363636363\n",
      "• 'vrai' => Précision: 0.9883720930232558 - Rappel: 0.9714285714285714\n",
      "# Global => Précision: 0.9883720930232558 - Rappel: 0.9714285714285714\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.36363636363636354\n",
      "• 'vrai' => Précision: 0.9827586206896551 - Rappel: 0.9771428571428571\n",
      "# Global => Précision: 0.9827586206896551 - Rappel: 0.9771428571428571\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.2909090909090908\n",
      "• 'vrai' => Précision: 0.9661016949152542 - Rappel: 0.9771428571428571\n",
      "# Global => Précision: 0.9661016949152542 - Rappel: 0.9771428571428571\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.21818181818181803\n",
      "• 'vrai' => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "# Global => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.14545454545454528\n",
      "• 'vrai' => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "# Global => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.07272727272727254\n",
      "• 'vrai' => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "# Global => Précision: 0.9558011049723757 - Rappel: 0.9885714285714285\n",
      "Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\n"
     ]
    }
   ],
   "source": [
    "# YOLOv4\n",
    "import numpy as np\n",
    "\n",
    "DOSSIER_SORTIE = \"predictions/yolov4/\"\n",
    "\n",
    "# en raison des limites du fichier dans Github, le poids YOLOv4 est téléchargeable depuis Google Drive:\n",
    "# https://drive.google.com/file/d/1-BhVjp-AaIMeWKC0veV_WWac2zYzX4Ye/view?usp=sharing\n",
    "FICHIER_POIDS = \"weights/yolov4_best.weights\"\n",
    "FICHIER_CFG = \"weights/yolov4.cfg\"\n",
    "\n",
    "DIMENSIONS_ENTREE = 608\n",
    "\n",
    "yolov4 = cv2.dnn.readNet(FICHIER_POIDS, FICHIER_CFG)\n",
    "global_pr_courbe = [ [], []] # courbe global de model \n",
    "evaluations_pr_courbes = [] # liste des courbe pour chaque evaluation \n",
    "for eve_id in range(len(types_evaluations)):\n",
    "     evaluations_pr_courbes.append([[],[]])\n",
    "\n",
    "conf_seuil_current = CONF_SEUIL_MAX\n",
    "while conf_seuil_current >= CONF_SEUIL_MIN:\n",
    "     print(\"\\nPour Seuils: IoU: \" + str(IOU_SEUIL) + \" - Confedence: \" + str(conf_seuil_current) )\n",
    "     conf_seuil_current -= CONF_PAS\n",
    "\n",
    "     g_tp = 0\n",
    "     g_prediction_total = 0\n",
    "\n",
    "     for eve_id, evaluation in enumerate(types_evaluations):\n",
    "          eve_tp = 0\n",
    "          eve_prediction_total = 0\n",
    "          eve_vrai_objets = evaluations_nombre_vrai_objet[eve_id]\n",
    "\n",
    "          # prepare l'image: RGB 416x416\n",
    "          for img_id, img in enumerate(img_buffer[eve_id]):\n",
    "               hauteur, largeur,_ = img.shape\n",
    "\n",
    "               blob = cv2.dnn.blobFromImage(img, 1/255, (DIMENSIONS_ENTREE, DIMENSIONS_ENTREE), (0,0,0), swapRB=True, crop=False)\n",
    "               yolov4.setInput(blob)\n",
    "               output_layers_names = yolov4.getUnconnectedOutLayersNames()\n",
    "               layerOutputs = yolov4.forward(output_layers_names)\n",
    "\n",
    "               boxes = []\n",
    "               confidences = []\n",
    "               class_ids = []\n",
    "\n",
    "               for output in layerOutputs:\n",
    "                   for detection in output:\n",
    "                       scores = detection[5:]\n",
    "                       class_id = np.argmax(scores)\n",
    "                       confidence = scores[class_id]\n",
    "                       if confidence >= conf_seuil_current:\n",
    "                           center_x = int(detection[0] * largeur)\n",
    "                           center_y = int(detection[1]* hauteur)\n",
    "                           w = int(detection[2]* largeur)\n",
    "                           h = int(detection[3]* hauteur)\n",
    "                           x = int(center_x - w/2)\n",
    "                           y = int(center_y - h/2)\n",
    "\n",
    "                           boxes.append([x, y, w, h])\n",
    "                           confidences.append((float(confidence)))\n",
    "                           class_ids.append(class_id)\n",
    "\n",
    "               indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "               output_img = img.copy()\n",
    "               \n",
    "               if len(indexes)>0:\n",
    "                    for i in indexes.flatten():\n",
    "                         g_prediction_total += 1\n",
    "                         eve_prediction_total += 1\n",
    "\n",
    "                         x, y, w, h = boxes[i]\n",
    "                         label = str(classes[class_ids[i]])\n",
    "                         confidence = str(round(confidences[i],2))\n",
    "\n",
    "                         cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "                         cv2.putText(output_img, label + \" \" + confidence, (x, y+20), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "\n",
    "                         for a in img_annotation[eve_id][img_id]:\n",
    "                              vrai_x = a[1]  \n",
    "                              vrai_y = a[2] \n",
    "                              vrai_largeur = a[3]  \n",
    "                              vrai_hauteur = a[4]  \n",
    "\n",
    "                              iou_score = IntersectionSurUnion(x, y, w, h, \n",
    "                                                                 a[1], a[2], a[3], a[4])\n",
    "\n",
    "                              # IoU >= seuil et class correct\n",
    "                              if iou_score >= IOU_SEUIL and class_ids[i] == a[0]:\n",
    "                                   g_tp += 1\n",
    "                                   eve_tp += 1\n",
    "\n",
    "               # ecrivez dans le diskoutput_\n",
    "               if conf_seuil_current >= ECRIRE_IMG_CONF_SEIL:\n",
    "                    cv2.imwrite(DOSSIER_SORTIE + types_evaluations[eve_id] + \"_\" + str(img_id) + \".PNG\", output_img)\n",
    "\n",
    "          # Calculate Precision et rappel pour l'evaluation current\n",
    "          eve_precision = (eve_tp / eve_prediction_total) if eve_prediction_total != 0 else 0\n",
    "          eve_rappel =  eve_tp / eve_vrai_objets\n",
    "\n",
    "          evaluations_pr_courbes[eve_id][0].append(eve_rappel)\n",
    "          evaluations_pr_courbes[eve_id][1].append(eve_precision)\n",
    "\n",
    "          print(\"• '\" + types_evaluations[eve_id] + \"' => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "    \n",
    "     # Global\n",
    "     g_precision = (g_tp / g_prediction_total) if g_prediction_total != 0 else 0\n",
    "     g_rappel =  g_tp / g_vrai_objets_total\n",
    "\n",
    "     global_pr_courbe[0].append(g_rappel)\n",
    "     global_pr_courbe[1].append(g_precision)\n",
    "     \n",
    "     print(\"# Global => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "\n",
    "# Courbe global\n",
    "print(\"Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\")\n",
    "DessinerCourbePrecisionRappel(global_pr_courbe[0], global_pr_courbe[1], \"Global\", IOU_SEUIL, DOSSIER_SORTIE)\n",
    "\n",
    "# Courbe pour chaque type d'evaluation\n",
    "for eve_id, nom_eve in enumerate(types_evaluations):\n",
    "     DessinerCourbePrecisionRappel( evaluations_pr_courbes[eve_id][0], evaluations_pr_courbes[eve_id][1], nom_eve, IOU_SEUIL, DOSSIER_SORTIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.8\n",
      "• 'vrai' => Précision: 0.9741379310344828 - Rappel: 0.6457142857142857\n",
      "# Global => Précision: 0.9741379310344828 - Rappel: 0.6457142857142857\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.7272727272727273\n",
      "• 'vrai' => Précision: 0.9752066115702479 - Rappel: 0.6742857142857143\n",
      "# Global => Précision: 0.9752066115702479 - Rappel: 0.6742857142857143\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.6545454545454545\n",
      "• 'vrai' => Précision: 0.953125 - Rappel: 0.6971428571428572\n",
      "# Global => Précision: 0.953125 - Rappel: 0.6971428571428572\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.5818181818181818\n",
      "• 'vrai' => Précision: 0.9323308270676691 - Rappel: 0.7085714285714285\n",
      "# Global => Précision: 0.9323308270676691 - Rappel: 0.7085714285714285\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.509090909090909\n",
      "• 'vrai' => Précision: 0.9084507042253521 - Rappel: 0.7371428571428571\n",
      "# Global => Précision: 0.9084507042253521 - Rappel: 0.7371428571428571\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.4363636363636363\n",
      "• 'vrai' => Précision: 0.8733333333333333 - Rappel: 0.7485714285714286\n",
      "# Global => Précision: 0.8733333333333333 - Rappel: 0.7485714285714286\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.36363636363636354\n",
      "• 'vrai' => Précision: 0.869281045751634 - Rappel: 0.76\n",
      "# Global => Précision: 0.869281045751634 - Rappel: 0.76\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.2909090909090908\n",
      "• 'vrai' => Précision: 0.8170731707317073 - Rappel: 0.7657142857142857\n",
      "# Global => Précision: 0.8170731707317073 - Rappel: 0.7657142857142857\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.21818181818181803\n",
      "• 'vrai' => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "# Global => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.14545454545454528\n",
      "• 'vrai' => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "# Global => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "\n",
      "Pour Seuils: IoU: 0.5 - Confedence: 0.07272727272727254\n",
      "• 'vrai' => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "# Global => Précision: 0.8121212121212121 - Rappel: 0.7657142857142857\n",
      "Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\n"
     ]
    }
   ],
   "source": [
    "# YOLOv3\n",
    "import numpy as np\n",
    "\n",
    "DOSSIER_SORTIE = \"predictions/yolov3/\"\n",
    "\n",
    "# en raison des limites du fichier dans Github, le poids YOLOv3 est téléchargeable depuis Google Drive:\n",
    "# https://drive.google.com/drive/folders/1SkusOM-0fFi_aT8VAhUIiL6j27YnoR7p?usp=sharing\n",
    "FICHIER_POIDS = \"weights/yolov3_training_last.weights\"\n",
    "FICHIER_CFG = \"weights/yolov3.cfg\"\n",
    "\n",
    "DIMENSIONS_ENTREE = 416\n",
    "\n",
    "yolov3 = cv2.dnn.readNet(FICHIER_POIDS, FICHIER_CFG)\n",
    "global_pr_courbe = [ [], []] # courbe global de model \n",
    "evaluations_pr_courbes = [] # liste des courbe pour chaque evaluation \n",
    "for eve_id in range(len(types_evaluations)):\n",
    "     evaluations_pr_courbes.append([[],[]])\n",
    "\n",
    "conf_seuil_current = CONF_SEUIL_MAX\n",
    "while conf_seuil_current >= CONF_SEUIL_MIN:\n",
    "     print(\"\\nPour Seuils: IoU: \" + str(IOU_SEUIL) + \" - Confedence: \" + str(conf_seuil_current) )\n",
    "     conf_seuil_current -= CONF_PAS\n",
    "\n",
    "     g_tp = 0\n",
    "     g_prediction_total = 0\n",
    "\n",
    "     for eve_id, evaluation in enumerate(types_evaluations):\n",
    "          eve_tp = 0\n",
    "          eve_prediction_total = 0\n",
    "          eve_vrai_objets = evaluations_nombre_vrai_objet[eve_id]\n",
    "\n",
    "          # prepare l'image: RGB 416x416\n",
    "          for img_id, img in enumerate(img_buffer[eve_id]):\n",
    "               hauteur, largeur,_ = img.shape\n",
    "\n",
    "               blob = cv2.dnn.blobFromImage(img, 1/255, (DIMENSIONS_ENTREE, DIMENSIONS_ENTREE), (0,0,0), swapRB=True, crop=False)\n",
    "               yolov3.setInput(blob)\n",
    "               output_layers_names = yolov3.getUnconnectedOutLayersNames()\n",
    "               layerOutputs = yolov3.forward(output_layers_names)\n",
    "\n",
    "               boxes = []\n",
    "               confidences = []\n",
    "               class_ids = []\n",
    "\n",
    "               for output in layerOutputs:\n",
    "                   for detection in output:\n",
    "                       scores = detection[5:]\n",
    "                       class_id = np.argmax(scores)\n",
    "                       confidence = scores[class_id]\n",
    "                       if confidence >= conf_seuil_current:\n",
    "                           center_x = int(detection[0] * largeur)\n",
    "                           center_y = int(detection[1]* hauteur)\n",
    "                           w = int(detection[2]* largeur)\n",
    "                           h = int(detection[3]* hauteur)\n",
    "                           x = int(center_x - w/2)\n",
    "                           y = int(center_y - h/2)\n",
    "\n",
    "                           boxes.append([x, y, w, h])\n",
    "                           confidences.append((float(confidence)))\n",
    "                           class_ids.append(class_id)\n",
    "\n",
    "               indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "               output_img = img.copy()\n",
    "               \n",
    "               if len(indexes)>0:\n",
    "                    for i in indexes.flatten():\n",
    "                         g_prediction_total += 1\n",
    "                         eve_prediction_total += 1\n",
    "\n",
    "                         x, y, w, h = boxes[i]\n",
    "                         label = str(classes[class_ids[i]])\n",
    "                         confidence = str(round(confidences[i],2))\n",
    "\n",
    "                         cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "                         cv2.putText(output_img, label + \" \" + confidence, (x, y+20), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "\n",
    "                         for a in img_annotation[eve_id][img_id]:\n",
    "                              vrai_x = a[1]  \n",
    "                              vrai_y = a[2] \n",
    "                              vrai_largeur = a[3]  \n",
    "                              vrai_hauteur = a[4]  \n",
    "\n",
    "                              iou_score = IntersectionSurUnion(x, y, w, h, \n",
    "                                                                 a[1], a[2], a[3], a[4])\n",
    "\n",
    "                              # IoU >= seuil et class correct\n",
    "                              if iou_score >= IOU_SEUIL and class_ids[i] == a[0]:\n",
    "                                   g_tp += 1\n",
    "                                   eve_tp += 1\n",
    "\n",
    "               # ecrivez dans le diskoutput_\n",
    "               if conf_seuil_current >= ECRIRE_IMG_CONF_SEIL:\n",
    "                    cv2.imwrite(DOSSIER_SORTIE + types_evaluations[eve_id] + \"_\" + str(img_id) + \".PNG\", output_img)\n",
    "\n",
    "          # Calculate Precision et rappel pour l'evaluation current\n",
    "          eve_precision = (eve_tp / eve_prediction_total) if eve_prediction_total != 0 else 0\n",
    "          eve_rappel =  eve_tp / eve_vrai_objets\n",
    "\n",
    "          evaluations_pr_courbes[eve_id][0].append(eve_rappel)\n",
    "          evaluations_pr_courbes[eve_id][1].append(eve_precision)\n",
    "\n",
    "          print(\"• '\" + types_evaluations[eve_id] + \"' => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "    \n",
    "     # Global\n",
    "     g_precision = (g_tp / g_prediction_total) if g_prediction_total != 0 else 0\n",
    "     g_rappel =  g_tp / g_vrai_objets_total\n",
    "\n",
    "     global_pr_courbe[0].append(g_rappel)\n",
    "     global_pr_courbe[1].append(g_precision)\n",
    "     \n",
    "     print(\"# Global => Précision: \" + str(eve_precision) + \" - Rappel: \" + str(eve_rappel))\n",
    "\n",
    "# Courbe global\n",
    "print(\"Dessiner la courbe Précision-Rappel et calculer la précision moyenne...\")\n",
    "DessinerCourbePrecisionRappel(global_pr_courbe[0], global_pr_courbe[1], \"Global\", IOU_SEUIL, DOSSIER_SORTIE)\n",
    "\n",
    "# Courbe pour chaque type d'evaluation\n",
    "for eve_id, nom_eve in enumerate(types_evaluations):\n",
    "     DessinerCourbePrecisionRappel( evaluations_pr_courbes[eve_id][0], evaluations_pr_courbes[eve_id][1], nom_eve, IOU_SEUIL, DOSSIER_SORTIE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
