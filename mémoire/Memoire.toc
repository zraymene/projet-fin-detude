\babel@toc {french}{}\relax 
\contentsline {chapter}{Remerciements}{i}{Doc-Start}%
\contentsline {chapter}{Résumé}{i}{Doc-Start}%
\contentsline {chapter}{Abstract}{i}{Doc-Start}%
\contentsline {chapter}{Liste des tableaux}{i}{Doc-Start}%
\contentsline {chapter}{Table des figures}{i}{chapter*.1}%
\contentsline {chapter}{\numberline {1}La détection d'objets}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Objectif}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Localisation d'objet}{4}{subsection.1.2.1}%
\contentsline {subsubsection}{Boîte englobante (Bounding Box)}{4}{section*.7}%
\contentsline {subsubsection}{Mask (niveau de pixel)}{5}{section*.9}%
\contentsline {subsection}{\numberline {1.2.2}Classification d'objet}{6}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Historique}{7}{section.1.3}%
\contentsline {section}{\numberline {1.4}Les applications de la détection d'objets}{8}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Reconnaissance optique de caractères (OCR)}{8}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Voitures autonomes}{9}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Biométrie}{10}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Reconnaissance d'activités}{11}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}Imagerie médicale}{12}{subsection.1.4.5}%
\contentsline {subsection}{\numberline {1.4.6}Robotique}{13}{subsection.1.4.6}%
\contentsline {subsection}{\numberline {1.4.7}Production industrielle}{14}{subsection.1.4.7}%
\contentsline {subsection}{\numberline {1.4.8}Surveillance et sécurité}{14}{subsection.1.4.8}%
\contentsline {subsection}{\numberline {1.4.9}Recherche visuelle}{15}{subsection.1.4.9}%
\contentsline {section}{\numberline {1.5}Conclusion}{16}{section.1.5}%
\contentsline {chapter}{\numberline {2}Détection d'objets et apprentissage profond}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{18}{section.2.1}%
\contentsline {section}{\numberline {2.2}Concepts de base}{19}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Les réseaux de neurones convolutifs (CNN)}{19}{subsection.2.2.1}%
\contentsline {subsubsection}{Couche de convolution}{20}{section*.23}%
\contentsline {subsubsection}{Pooling Layer}{20}{section*.25}%
\contentsline {subsubsection}{Fully Connected Layer (FC)}{21}{section*.27}%
\contentsline {subsection}{\numberline {2.2.2}L'apprentissage par transfert}{21}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Architectures CNN populaires}{22}{subsection.2.2.3}%
\contentsline {subsubsection}{AlexNet}{22}{section*.30}%
\contentsline {subsubsection}{VGG-16}{23}{section*.32}%
\contentsline {subsubsection}{ResNet}{24}{section*.34}%
\contentsline {subsubsection}{GoogLeNet}{25}{section*.36}%
\contentsline {subsubsection}{Darknet-53}{26}{section*.38}%
\contentsline {section}{\numberline {2.3}Fonction de perte pour la détection d'objet}{27}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Perte de Classification}{27}{subsection.2.3.1}%
\contentsline {subsubsection}{Hinge loss}{27}{section*.40}%
\contentsline {subsubsection}{Cross entropy loss}{28}{section*.41}%
\contentsline {subsection}{\numberline {2.3.2}Perte de Localistaion}{28}{subsection.2.3.2}%
\contentsline {subsubsection}{Squared Loss}{28}{section*.42}%
\contentsline {subsubsection}{Residual Sum of Squares (RSS)}{28}{section*.43}%
\contentsline {subsubsection}{Mean Squared Error (MSE)}{29}{section*.44}%
\contentsline {subsubsection}{Absolute loss}{29}{section*.45}%
\contentsline {subsubsection}{Sum of Absolute Differences (SAD)}{29}{section*.46}%
\contentsline {subsubsection}{Mean Absolute Error (MAE)}{29}{section*.47}%
\contentsline {section}{\numberline {2.4}Génération de proposition}{30}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Méthodes traditionnelles de vision par ordinateur}{30}{subsection.2.4.1}%
\contentsline {subsubsection}{Score d'objectivité}{30}{section*.48}%
\contentsline {subsubsection}{Superpixels fusionnant}{30}{section*.49}%
\contentsline {subsubsection}{Segmentation des semences}{31}{section*.50}%
\contentsline {subsection}{\numberline {2.4.2}Méthodes basées sur des ancres}{31}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Méthodes basées sur les points clés}{32}{subsection.2.4.3}%
\contentsline {subsubsection}{Méthodes basées sur les coins}{32}{section*.52}%
\contentsline {subsubsection}{Méthodes basées sur le centre}{32}{section*.53}%
\contentsline {section}{\numberline {2.5}Apprentissage de la représentation des caractéristiques}{33}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Apprentissage de fonctionnalités multi-échelles}{33}{subsection.2.5.1}%
\contentsline {subsubsection}{Pyramide d'images}{33}{section*.54}%
\contentsline {subsubsection}{Fonctionnalités intégrées}{33}{section*.55}%
\contentsline {subsubsection}{Pyramide de prédiction}{34}{section*.56}%
\contentsline {subsubsection}{Pyramide des fonctionnalités}{34}{section*.57}%
\contentsline {subsection}{\numberline {2.5.2}Codage des caractéristiques régionales}{34}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}Raisonnement contextuel}{35}{subsection.2.5.3}%
\contentsline {subsubsection}{Raisonnement contextuel global}{35}{section*.58}%
\contentsline {subsubsection}{Raisonnement du contexte de la région}{35}{section*.59}%
\contentsline {subsection}{\numberline {2.5.4}Apprentissage des caractéristiques déformables}{36}{subsection.2.5.4}%
\contentsline {section}{\numberline {2.6}Les méthodes de détections d'objets basées sur l'apprentissage profond}{36}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Détecteurs à Deux-étapes}{36}{subsection.2.6.1}%
\contentsline {subsubsection}{RCNN}{36}{section*.60}%
\contentsline {subsubsection}{Fast-RCNN}{37}{section*.63}%
\contentsline {subsubsection}{Faster-RCNN}{38}{section*.65}%
\contentsline {subsection}{\numberline {2.6.2}Détecteurs à Un-étapes}{39}{subsection.2.6.2}%
\contentsline {subsubsection}{YOLO (You Only Look Once)}{40}{section*.67}%
\contentsline {subsubsection}{YOLOv3}{40}{section*.69}%
\contentsline {subsubsection}{SSD (Single Shot MultiBox Detector)}{41}{section*.72}%
\contentsline {section}{\numberline {2.7}Métriques pour l'évaluation des systèmes de détection d'objets}{42}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Intersection sur Union (IoU)}{42}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Matrice de confusion}{43}{subsection.2.7.2}%
\contentsline {paragraph}{Vrai positif (TP):}{43}{section*.76}%
\contentsline {paragraph}{Faux positif (FP):}{43}{section*.77}%
\contentsline {paragraph}{Faux négatif (FN):}{44}{section*.78}%
\contentsline {paragraph}{Vrai négatif (TN):}{44}{section*.79}%
\contentsline {subsection}{\numberline {2.7.3}Précision}{44}{subsection.2.7.3}%
\contentsline {subsection}{\numberline {2.7.4}Rappel}{44}{subsection.2.7.4}%
\contentsline {subsection}{\numberline {2.7.5}Précision x Rappel courbe}{44}{subsection.2.7.5}%
\contentsline {subsection}{\numberline {2.7.6}Précision moyenne (AP)}{45}{subsection.2.7.6}%
\contentsline {subsection}{\numberline {2.7.7}Précision moyenne moyenne (mAP)}{45}{subsection.2.7.7}%
\contentsline {section}{\numberline {2.8}Bases de données d'évaluation}{46}{section.2.8}%
\contentsline {section}{\numberline {2.9}Conclusion}{46}{section.2.9}%
\contentsline {chapter}{\numberline {3}Implemnetation de détection d'objets et apprentissage profond}{47}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{48}{section.3.1}%
\contentsline {subsubsection}{Acquisition d'image:}{49}{section*.82}%
\contentsline {subsubsection}{Localistaion des URL:}{49}{section*.83}%
\contentsline {subsubsection}{Numériser l'URL :}{49}{section*.84}%
\contentsline {section}{\numberline {3.2}Méthodes de détection d'objets choisies}{50}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}YOLOv3}{50}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}YOLOv4}{50}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}YOLOv5}{50}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Ensemble de données d'entraînement}{51}{section.3.3}%
\contentsline {subsubsection}{Création de textures:}{54}{section*.89}%
\contentsline {subsubsection}{Création de maillage:}{54}{section*.90}%
\contentsline {subsubsection}{Modification de maillage:}{55}{section*.91}%
\contentsline {subsubsection}{Attribuer la texture au maillage:}{55}{section*.92}%
\contentsline {subsubsection}{Effets supplémentaires:}{55}{section*.93}%
\contentsline {subsubsection}{Le Rendu:}{55}{section*.94}%
\contentsline {subsection}{\numberline {3.3.1}Outil Utiliser}{56}{subsection.3.3.1}%
\contentsline {subsubsection}{Libre Office Word:}{56}{section*.96}%
\contentsline {subsubsection}{Blender:}{56}{section*.97}%
\contentsline {subsubsection}{LabelImg:}{57}{section*.98}%
\contentsline {subsubsection}{Roboflow:}{57}{section*.99}%
\contentsline {section}{\numberline {3.4}Training}{57}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}YOLOv3}{57}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}YOLOv4}{57}{subsection.3.4.2}%
\contentsline {paragraph}{1-}{57}{section*.100}%
\contentsline {paragraph}{2-}{58}{section*.102}%
\contentsline {paragraph}{3-}{58}{section*.104}%
\contentsline {paragraph}{4-}{58}{section*.106}%
\contentsline {paragraph}{5-}{59}{section*.108}%
\contentsline {paragraph}{-}{59}{section*.109}%
\contentsline {paragraph}{-}{59}{section*.110}%
\contentsline {paragraph}{-}{59}{section*.111}%
\contentsline {paragraph}{-}{59}{section*.112}%
\contentsline {paragraph}{6-}{60}{section*.115}%
\contentsline {paragraph}{-}{60}{section*.116}%
\contentsline {paragraph}{-}{60}{section*.117}%
\contentsline {paragraph}{-}{60}{section*.118}%
\contentsline {paragraph}{-}{60}{section*.119}%
\contentsline {paragraph}{-}{61}{section*.120}%
\contentsline {paragraph}{7-}{61}{section*.122}%
\contentsline {paragraph}{8-}{61}{section*.124}%
\contentsline {paragraph}{Condition spéciale :}{61}{section*.126}%
\contentsline {subsection}{\numberline {3.4.3}YOLOv5}{62}{subsection.3.4.3}%
\contentsline {paragraph}{1-}{62}{section*.128}%
\contentsline {paragraph}{2-}{62}{section*.130}%
\contentsline {paragraph}{3-}{62}{section*.132}%
\contentsline {paragraph}{-}{62}{section*.133}%
\contentsline {paragraph}{-}{62}{section*.134}%
\contentsline {paragraph}{-}{63}{section*.135}%
\contentsline {paragraph}{-}{63}{section*.136}%
\contentsline {subsection}{\numberline {3.4.4}Outil Utiliser}{63}{subsection.3.4.4}%
\contentsline {subsubsection}{Google Collab:}{63}{section*.138}%
\contentsline {subsubsection}{Python:}{63}{section*.139}%
\contentsline {subsubsection}{Darknet:}{63}{section*.140}%
\contentsline {subsubsection}{PyTorch:}{63}{section*.141}%
\contentsline {section}{\numberline {3.5}Testing}{64}{section.3.5}%
\contentsline {paragraph}{-}{64}{section*.142}%
\contentsline {paragraph}{-}{64}{section*.143}%
\contentsline {paragraph}{-}{64}{section*.144}%
\contentsline {paragraph}{-}{64}{section*.145}%
\contentsline {subsection}{\numberline {3.5.1}YOLOv3}{64}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}YOLOv4}{64}{subsection.3.5.2}%
\contentsline {paragraph}{Conclusion:}{68}{section*.150}%
\contentsline {subsection}{\numberline {3.5.3}YOLOv5}{68}{subsection.3.5.3}%
\contentsline {paragraph}{Conclusion:}{73}{section*.156}%
\contentsline {section}{\numberline {3.6}Conclusion Géneral}{73}{section.3.6}%
\contentsline {chapter}{Bibliographie}{74}{section.3.6}%
\contentsline {chapter}{Annexe}{76}{chapter*.157}%
