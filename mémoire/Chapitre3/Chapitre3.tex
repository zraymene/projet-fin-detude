% TODO:
%    - Chapitre 2:  
%         - More detail on YOLOv4 / YOLOv5
%    - Chapitre 3:
%         - Evluation pour chaque diffuclter
%         - Conclusion general
%

\chapter{Implemnetation de détection d'objets et apprentissage profond}
\newpage
\pagestyle{fancy}
\fancyhead[L]{\chaptername \ \thechapter}
\fancyhead[R]{Implemnetation de détection d'objets et apprentissage profond}
\renewcommand{\headrulewidth}{1pt}
\fancyfoot[C]{\thepage}

\section{Introduction} 
Dans notre travail, nous allons comparer trois modèles profond de la 
famille YOLO, à savoir YOLOv3, YOLOv4, et YOLOv5, car ceux sont des détecteurs à une étape qui fournissent une détection rapide avec une grande précision qui peut fonctionner dans des machines bas de gamme comme les systèmes embarqués.

Dans ce chapitre, nous présenterons la démarche d'évaluation suivie.
Nous commençons par une étape principale de création et de préparation de la base d'entraînement. Puis, nous effectuons un entraînement des trois modèles choisis pour l'étude; YOLOv3, YOLOv4, et YOLOv5. Enfin nous faisons des tests avec des images contenant plusieurs difficultés pour évaluer la capacité de généralisation des trois modèles dans des cas d'usage  spécifiques où le contenu est différent. 

\section{Création de l'ensemble de données d'entraînement}
Les algorithmes de détection d'objets sélectionnés relèvent de l'apprentissage en profondeur en raison de leur structure complexe et ils doivent être entraînés à l'aide d'un ensemble de données pour atteindre l'objectif requis. L'ensemble de données affecte fortement les performances des modèles, c'est pourquoi l'ensemble de données doit être robuste pour atteindre des performances plus élevées du modèle. mais nous devons d'abord comprendre ce que nous essayons de détecter.

          L'URL commence par 3 lettres 'w' consécutives et un point \(www.\) suivi d'une étiquette, l'étiquette est une série de lettres anglaises de a à z (non sensible à la casse) et peut également contenir des chiffres de 0 à 9, des traits d'union peuvent être ajoutés mais pas au début ni à la fin et ajouter plus de 1 consécutivement n'est pas autorisé, La longueur du libellé est comprise entre 3 et 63 caractères maximum. Au final, après un point, une extension est ajoutée. Les extensions les plus utilisées sont : ".com", ".net" et ".org". cette partie peut être nommée le nom de domaine.

          L'URL peut commencer par un protocole tel que \(http://\) ou \(https://\) pour le HTTP sécurisé, mais les clients Web modernes comme les navigateurs ajoutent automatiquement le protocole avant l'URL s'il n'en contient pas. L'URL peut également contenir après le nom de l'extension plus de données telles que le nom de fichier \(/index.html\) ou des sous-répertoires comme \(/dir1/dir2\)
          \begin{figure}[H]
               \centering
               \includegraphics[height=2cm,width=16cm]{Chapitre3/img_1.png}
               \caption{Structure d'un URL.}
               \label{img3}
               \end{figure}

          Nous avons créé des noms d'étiquettes aléatoires selon les conventions précédemment répertoriées avec l'extension définie ajoutée à la fin qui est : \(.com\), \(.net\), \(.org\), \(.fr\), \(.dz\), \(.ca\), \(.uk\). ces extensions sont largement répandues spécialement dans notre région. Nous avons ajouté quelques URL contenant des données supplémentaires à la fin, mais la majorité des ensembles de données se concentrent fortement sur le nom de domaine (étiquette et extension).
          
          Les méthodes de détection d'objet ne voient que les pixels, la lettre 'A' dans une police et diffèrent fortement d'une autre police, une lettre écrite à la main (manuscrit) peut également différer considérablement de sa contrepartie imprimée, elles ont toutes deux la même valeur sémantique mais écrites différemment. Ainsi, comme point de départ pour la création de l'ensemble de données, les URL imprimées sont utilisées et dessinées à l'aide de la police populaire \(Arial\). et pour la couleur, le noir est choisi.
          \begin{figure}[H]
               \centering
               \includegraphics[height=6cm,width=16cm]{Chapitre3/img_3.png}
               \caption{Diffrence d'ecritue de la lettre 'A'.}
               \label{img4}
               \end{figure}

          La plupart des impressions dans le monde se font sur du papier A4, dans cet esprit, l'ensemble de données contiendra des échantillons d'URL imprimés sur du papier au format A4. Les URL seront accompagnées de texte aléatoire écrit dans différentes langues : Latin, Arabe, Chinois, Russe et Indien.
          \begin{figure}[H]
               \centering
               \includegraphics[height=16cm,width=16cm]{Chapitre3/img_4.png}
               \caption{Exemple de documents générés.}
               \label{img5}
               \end{figure}

          Une fois les documents prêts, l'impression est la dernière étape, mais cette étape est coûteuse et fastidieuse, précisez lorsque la création d'un grand ensemble de données est requise. Une meilleure approche et moins coûteuse (presque 0 coût) qui est des données synthétiques, ce sont des informations (dans notre cas des images) qui sont fabriquées artificiellement plutôt que générées par le monde réel en tirant parti des algorithmes de rendu 3D photo réaliste existants.

          Les bases du rendu 3D consistent à transformer des données tridimensionnelles représentées dans une série de triangles appelés maillage en écran 2D. Un buffer de pixels appelé Textures peut être appliqué à ces mesh pour les afficher dessus. Des algorithmes supplémentaires peuvent être utilisés pour améliorer le résultat rendu à la qualité du monde réel, comme : l'éclairage et l'ombre.

          Le processus de génération de nos données synthétiques est divisé en plusieurs phases qui sont :
          \begin{figure}[H]
               \centering
               \includegraphics[height=10cm,width=16cm]{Chapitre3/img_5.png}
               \caption{Étapes des génération de données synthétiques.}
               \label{img6}
               \end{figure}

          \subsubsection{Création de textures:} Après avoir créé un document dans un logiciel de traitement de documents, il doit être exporté dans une image de dimension supérieure pour 	assurer une meilleure qualité lors du rendu.
          \subsubsection{Création de maillage:} Dans un logiciel d'infographie 3D comme Blender, un maillage de forme de papier A4 est créé.
          \subsubsection{Modification de maillage:} Les modifications et les transformations sont appliquées à l'ensemble du maillage ou à un groupe de sommets dans le but de simuler un papier du monde réel. 
          \subsubsection{Attribuer la texture au maillage:} La texture est chargée dans un logiciel 3D et affectée au maillage, ce qui affichera le pixel de texture au-dessus du maillage.
          \subsubsection{Effets supplémentaires:} Le résultat de la phase précédente peut sembler réaliste, mais des effets supplémentaires peuvent être ajoutés pour améliorer le réalisme, tels que l'éclairage, les ombres et une image d'arrière-plan. Dans Blender, il y a un effet sans fin qui peut être ajouté en utilisant des Shaders mais dans notre cas, les effets précédents sont suffisants.
          \subsubsection{Le Rendu:} C'est la phase finale où l'image de sortie est produite. Les dimensions de rendu sont sélectionnées pour imiter les photos prises par un téléphone mobile.
          

          Après avoir créé de nombreuses images simulées, elles doivent être étiquetées manuellement où la boîte d'URL liée dans chaque image est définie à la main, puis enregistrées à l'aide du format d'annotation d'image YOLO où chaque image a son fichier texte d'annotation unique '.txt' nommé de la même manière que le nom de l'image . Chaque ligne du fichier d'annotation est un objet de vérité terrain dans l'image représentée comme ceci "<classe d'objet> <x> <y> <largeur> <hauteur>"
          \begin{figure}[H]
               \centering
               \includegraphics[height=8cm,width=12cm]{Chapitre3/img_6.png}
               \caption{Structure de fichier du format d'annotation YOLO.}
               \label{img7}
               \end{figure}

          Ce format de ensemble de données ne fonctionnera que pour les versions de YOLO écrites en Darknet (YOLOv3 et YOLOv4) et ne sera pas reconnu par YOLOv5. une plate-forme est utilisée pour résoudre ce problème nommé Roboflow. Roboflow est une plate-forme wep qui héberge, annote et convertit tous les types de formats d'ensembles de données. Notre ensemble de données est téléchargé sur roboflow pour résoudre le problème précédent.
          
          On a créé totalement 160 images qui seront divisées comme suit: 80\% (127) images pour entrainement et 20\% (33) pour l'évaluation.

          \subsection{Les outils utilisés}
               \subsubsection{Libre Office Word:} est un traitement de texte et fait partie de la suite LibreOffice, une suite logicielle de productivité bureautique gratuite et open-source. Utilisé pour créer/modifier des documents et également les exporter au format PNG en tant que textures.
               \subsubsection{Blender:} est un ensemble d'outils logiciels d'infographie 3D gratuits et open-source utilisés pour créer des films d'animation, des effets visuels, de l'art, des modèles imprimés en 3D, des animations graphiques, des applications 3D interactives, la réalité virtuell. Utilisé pour générer les données synthétiques. 
               \subsubsection{LabelImg:} est un outil graphique d'annotation d'images. Il est écrit en Python et utilise Qt pour son interface graphique. Les annotations sont enregistrées sous forme de fichiers XML au format PASCAL VOC, le format utilisé par ImageNet. En outre, il prend également en charge les formats YOLO et CreateML. Utilisé pour étiqueter notre jeu de données et l'exporter au format YOLO.  
               \subsubsection{Roboflow:} est une plate-forme de vision par ordinateur qui permet aux utilisateurs de créer des modèles de vision par ordinateur plus rapidement et avec plus de précision grâce à la fourniture de meilleures techniques de collecte de données, de prétraitement et de l'entrainement de modèles. Utilisé pour résoudre le problème de conversion au format d'annotation YOLOv5.

% ======= ENVIRMEENTS ==========
\section{Environnement expérimental}
     \subsubsection{Machine locale} ordinateur local avec processeur Intel(R.) Core(TM) i7-8750H @ 2.20 GHz - 6 noyaux, RAM 8 GB et carte graphique GTX 1050. La machine est utilisée dans la création de l'ensemble des donnes et sur l'évaluation.
     \subsubsection{Google Collab} est un outil d'analyse de données et d'apprentissage automatique qui vous permet de combiner du code Python exécutable et du texte enrichi avec des graphiques, des images, HTML, LaTeX et plus encore dans un seul document stocké dans Google Drive. Il se connecte aux puissants environnements d'exécution de Google Cloud Platform et vous permet de partager facilement votre travail et de collaborer avec d'autres.
     \subsubsection{Python} est un langage de programmation généraliste de haut niveau. Sa philosophie de conception met l'accent sur la lisibilité du code avec l'utilisation d'une indentation significative via la règle du hors-jeu. Python est dynamiquement typé et ramassé. Il est utilisé pour créer des scripts pour automatiser les processus. 
     \subsubsection{OpenCV} est une bibliothèque libre, initialement développée par Intel, spécialisée dans le traitement d'images en temps réel. Dans notre traiveille, elle est utilisée pour lire et re-dimenssioner, dessiner les boîtes englobant et écrire les images sur le disk sur des formats compresser comme $PNG$.
     \subsubsection{Darknet} est un framework de réseau neuronal open source écrit en C et CUDA et prend en charge le calcul CPU et GPU. il était utilisé pour entraîner les modèles de détection d'objets YOLOv3 et YOLOv4.
     \subsubsection{PyTorch} est open-source gratuit et un cadre d'apprentissage automatique basé sur la bibliothèque Torch, utilisé pour des applications telles que la vision par ordinateur et le traitement du langage naturel.

% ======== TRAINING =============
\section{Entraînement des modèles}
     Les models sont entrainés sur $80\%$ (127 images) de l'ensemble des donnés. L'entraînement se fait sur les machines fournies par Google Colab.

     Les paramètres de l'entrainement de YOLOv3 sont: $416\times416$ pour les dimensions de l'image d'entrée, $2000$ lots maximum et les paramètres trouver dans le fichier de configuration de modèle: $classes$ est mis à 1 et $filters$ trouver avant la structure $yolo$ sont fixées à 18 en suivant cette formule: (n + 5) * 3 où n est le nombre des classes. l'entrainement a duré 7 heures.
     
     Pour YOLOv4, les dimensions de l'image d'entrée sont $608\times608$, 2000 lots maximum et les paramètres de configuration de modèle $classes$ et $filters$ sont mises à 1 et 18 respectivement comme nous l'avons fait avec YOLOv3. l'entrainement a également duré 7 heures.
     
     Pour YOLOv5, le modèle médium est choisi car qu'il y a moins de compromis entre précision et vitesse, les dimensions par défaut de l'image d'entrée $640\times640$ avec 30 nombres d'époques. Contrairement aux modèles précédents, ce modèle n'a pris que 15 minutes pour terminer l'entrainment, ce qui est beaucoup trés rapide.

     Darknet est le framework utilisé pour faire l'entrainement de YOLOv3 et YOLOv4 contrairement à YOLOv5 où PyTorch est le framework utilisé. Les poids pré-entraînés officiels sont choisi pour appliquer l'apprentissage par transfert. Les poids finaux des modèles sont téléchargés sur la machine locale pour être évalués.
     

% ========= TESING =============
\section{Évaluation des modèles}
     Les modèles sont évalué sur $20\%$ (33 images) de l'ensemble des donnes le seuil de $IoU$ mis à 0.5.
     
     YOLOv3 a donné $70.53\%$ comme précision moyenne mais la précision baisse après que le rappel atteigne $0.75$.

     YOLOv4 a donné $90.91\%$ comme précision moyenne mais la précision baisse après que le rappel atteigne $0.98$.

     YOLOv5 a donné $88.63\%$ comme précision moyenne mais la précision baisse après que le rappel atteigne $0.91$.
     
     \begin{figure}[H]
               \centering
               \includegraphics[height=8cm,width=15cm]{Chapitre3/yolov3_pr_Global.png}
               \caption{YOLOv3: Courbe Précision-Rappel et La Précision Moyenne.}
               \label{y3_pr}
               \end{figure}
     \begin{figure}[H]
               \centering
               \includegraphics[height=8cm,width=15cm]{Chapitre3/yolov4_pr_global.png}
               \caption{YOLOv4: Courbe Précision-Rappel et La Précision Moyenne.}
               \label{y4_pr}
               \end{figure}
     \begin{figure}[H]
               \centering
               \includegraphics[height=8cm,width=15cm]{Chapitre3/yolov5_pr_global.png}
               \caption{YOLOv5: Courbe Précision-Rappel et La Précision Moyenne.}
               \label{y5_pr}
               \end{figure}
     
     %========= DIFFICULTIES ==========
     \subsection{Les difficultés}

          Nous voulons tester comment les modèles réagissent à différents types de :
          \paragraph{-} Police de caractère.
          \paragraph{-} Couleur.
          \paragraph{-} Transformation (Rotation).
          \paragraph{-} URL avec préfixe de protocole https
          \paragraph{-} Manuscrits.
               
          La métrique d'évaluation finale est la précision moyenne (AP) qui donne des performances précises du modèle qui est calculé à partir de la courbe de rappel de précision
          Le seuil d'intersection sur union (IoU) est $0.5$.
          \paragraph

           \begin{tabular}{|C|C|C|C| }
                \hline
                modèle      & yolo-v3      &   yolo-v4     &    yolo-v5 \\
                \hline
                couleurs     & $31,17\%$AP  &  $54,55\%$AP  &  $27,27\%$AP \\
                \hline
                Police(font) &  $72,73\%$AP & $84,29\%$AP   &  $88,07\%$AP \\ 
                \hline
                Link(https)  & $12,12\%$AP  &  $28,9\%$AP   &  $13,64\%$AP \\
                \hline
                Manuscript   & $0,0\%$AP    &  $0,0\%$AP    &  $0,0\%$AP  \\
                \hline
                Rotation     & 180° ($27,27\%$AP) & 180° ($18,18\%$AP)  & 180° ($18,18\%$AP) \\
                             & 90°($0,0\%$AP)     & 90°($0,0\%$AP)      & 90°($0,0\%$AP) \\             
                \hline
              
                \end{tabular}

          % ---------- YOLOv3 -------------
          \subsubsection{YOLOv3}
          En général,, le modèle a donné $43.12\%$ comme précision moyenne (AP). 
           \begin{figure}[H]
                    \centering
                     \includegraphics[height=10cm,width=17cm]{Chapitre3/yolov3_pr_Global.png}
                     \caption{YOLOv3: Courbe Précision-Rappel et Précision Moyenne de modele.}
                     \label{y3_t0}
                     \end{figure}

           \paragraph{1-} Police de caractère.
              Il y  3 types des polices  et nous allons faites des tests par yolo-v3 et afficher les résultats.
           \begin{figure}[H]
                   \centering
                    \includegraphics[height=8cm,width=14cm]{Chapitre3/y3-t2.png}
                    \caption{YOLOv3: Test des URL écrites en police Arial.}
                    \label{y3_t1}
                    \end{figure}
               
           \paragraph{-}Le résultat 
           la précision moyenne de l'algorithme yolo-v3 dans cette partie est $72.73\%$.

           \paragraph{2-} Couleur.
           \paragraph{-}  On utilise 15 éléments ont couleurs
            Le résultat qui nous avons détecté et trouver est 7 éléments,  la précision moyenne est de $31.17\%$
           \begin{figure}[H]
               \centering
                \includegraphics[height=10cm,width=14cm]{Chapitre3/y3-t3.png}
                \caption{YOLOv3: test des URL écrites dans différentes couleurs.}
                \label{y3_t3}
                \end{figure}
           
           \paragraph{3-} Transformation (Rotation).
           \paragraph{-} Pour la rotation de 90 ne donne aucun résultat.
           \begin{figure}[H]
               \centering
                \includegraphics[height=10cm,width=12cm]{Chapitre3/y3-t5.png}
                \caption{YOLOv3: test des URL écrites en rotation $90°$.}
                \label{y3_t5}
                \end{figure}
           
           \paragraph{-} Pour une rotation de 180, le score est $27.27\%$.
           \begin{figure}[H]
               \centering
                \includegraphics[height=10cm,width=12cm]{Chapitre3/y3-t6.png}
                \caption{YOLOv3: test des URL écrites en rotation $180°$.}
                \label{y3_t6}
                \end{figure}

           \paragraph{3-}Link (https)
           \paragraph{-} Dans cette étude, nous constatons que  la précision moyenne  est faible $12.12\%$ et nous avons remarqué que dans certains cas, nous avons détecté le modèle $www$ dans le modèle $http$.
           
           \begin{figure}[H]
               \centering
                \includegraphics[height=10cm,width=12cm]{Chapitre3/y3-t4.png}
                \caption{yolov3 : tester les URL écrites avec prefixe protocol HTTPS.}
                \label{y3_t4}
                \end{figure}


           \paragraph{4-} Manuscrits.
           \paragraph{-} Dans cette étude, nous n'avons pas obtenu de résultats.

           \begin{figure}[H]
               \centering
                \includegraphics[height=10cm,width=12cm]{Chapitre3/y3-t7.png}
                \caption{YOLOv3: Test des URL écrites en manuscrit.}
                \label{y3_t7}
                \end{figure}

           \paragraph{Conclusion:} Ces résultats nous permettent de dire que Yolov3 a été capable d'obtenir d'excellents résultats malgré les changements dans les images.  
           
           
                

          % ---------- YOLOv4 -------------
          \subsubsection{YOLOv4}
          Ce modèle est formé en utilisant 16 images par lot et 2000 lots maximum.

          Généralement, le modèle a atteint $53,12\%$ en tant que précision moyenne (AP)
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/yolov4_pr_global.png}
                    \caption{YOLOv4: Courbe Précision-Rappel et Précision Moyenne de modele.}
                    \label{y4_pr}
                    \end{figure}
               
          Le modèle atteint une précision de moyenne $100.00\%$ sur les ULR écrits en police Arial. L'épaisseur des lettres n'affecte pas les résultats. Cependant, plus l'image est réduite à une taille plus petite, plus la précision diminue.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=8cm,width=17cm]{Chapitre3/y4_t1.png}
                    \caption{YOLOv4 : Test des URL écrites en police Arial.}
                    \label{y4_t1}
                    \end{figure}
               
          Le modèle atteint une précision moyenne de $84.29\%$ sur les URL écrites dans différentes polices.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=8cm,width=17cm]{Chapitre3/y4_t2.png}
                    \caption{YOLOv4 : Test des URL écrites dans différentes polices.}
                    \label{y4_t2}
                    \end{figure}

          Le modèle atteint une précision moyenne de $54.44\%$ avec des URL de couleurs différentes (lettres et arrière-plan).
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=9cm,width=17cm]{Chapitre3/y4_t3.png}
                    \caption{YOLOv4 : test des URL écrites dans différentes couleurs.}
                    \label{y4_t3}
                    \end{figure}

          Dans le cas des rotations, les modèles échouent totalement lorsque l'entrée est tournée de $90°$, d'autre part, une rotation de $180°$ n'affecte pas la précision du modèle.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=12cm,width=16cm]{Chapitre3/y4_t4.png}
                    \caption{YOLOv4 : test des URL écrites dans différentes rotations.}
                    \label{y4_t4}
                    \end{figure}
               
          Dans le cas d'URL avec le protocole de préfixe https, le modèle ne parvient pas à donner des prédictions précises avec $28.9\%$ précision moyenne
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=9cm,width=17cm]{Chapitre3/yolov4_https.png}
                    \caption{YOLOv4 : test des URL écrites avec prefixe protocol HTTPS.}
                    \label{y4_https}
                    \end{figure}
               
          Enfin, le modèle ne parvient pas à détecter les URL écrites en manuscrit.
          \paragraph{Conclusion:} Le modèle est fortement affecté par la mise à l'échelle, plus la taille est petite, plus la précision du modèle est faible. Différentes polices réduisent la précision du modèle, mais en plus petites quantités $~ 5\%$. Les couleurs affectent fortement la précision des modèles à la fois en cas de lettres colorées et de couleur de fond. Pour la rotation, les rotations à $90 degrés$ cassent le modèle à $180 degrés$, la précision n'est pas affectée. Enfin, les URL des manuscrits ne sont pas reconnaissables par le modèle, même les faux objets de vérité n'ont pas été détectés.
               
          % ---------- YOLOv5 -------------
          \subsubsection{YOLOv5}
          Ce modèle a été formé avec 640x640 comme image d'entrée et 30 époques.
               
          Généralement, le modèle a atteint $44,19\%$ en tant que précision moyenne (AP)
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/yolov5_pr_global.png}
                    \caption{YOLOv5: Courbe Précision-Rappel et Précision Moyenne de modéle.}
                    \label{y4_pr}
                    \end{figure}
               
               
          Le modèle réussit à détecter les URL écrites à l'aide de la police Arial de couleur noire avec $100\%$ de précision moyenne, l'épaisseur de la police n'affecte pas les résultats. 
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/y5_t1.png}
                    \caption{YOLOv5 : Test des URL écrites en police Arial.}
                    \label{y5_t1}
                    \end{figure}

          Le modèle fait un excellent travail en détectant les URL écrites dans une police différente avec $88.05\%$ de précision moyenne.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/y5_t2.png}
                    \caption{YOLOv5: Test des URL écrites dans différentes polices.}
                    \label{y5_t2}
                    \end{figure}

          Pour les lettres d'URL colorées et les URL de couleur d'arrière-plan, le modèle ne parvient pas à les détecter correctement avec $27.27\%$ précision moyenne.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/y5_t3.png}
                    \caption{YOLOv5 : test des URL écrites dans différentes couleurs.}
                    \label{y5_t3}
                    \end{figure}

          Pour les transformations, la mise à l'échelle n'affecte pas les résultats, par contre, les rotations affectent grandement la précision des modèles. Dans les rotations à $90 °$, le modèle échoue totalement à détecter les URL avec $0\%$ de précision, mais à $180 °$, le modèle détecte les URL correctement, comme si la rotation ne s'était jamais produite.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=10cm,width=17cm]{Chapitre3/y5_t4.png}
                    \caption{YOLOv5: test des URL écrites dans différentes rotations.}
                    \label{y5_t4}
                    \end{figure}
               
          Dans le cas d'URL avec le protocole de préfixe https, le modèle ne parvient pas à donner des prédictions précises avec $13.6\%$ précision moyenne
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=9cm,width=17cm]{Chapitre3/yolov5_https.png}
                    \caption{YOLOv5 : test des URL écrites avec prefixe protocol HTTPS.}
                    \label{y5_https}
                    \end{figure}
               

          Enfin, pour les URL manuscrites, le modèle échoue totalement à effectuer une détection correcte. Cependant, il a détecté la première partie de l'URL $www.$ mais ne parvient pas à détecter l'intégralité de l'URL.
          \begin{figure}[H]
                    \centering
                    \includegraphics[height=11cm,width=12cm]{Chapitre3/y5_t5.jpg}
                    \caption{YOLOv5 : Test des URL écrites en manuscrit.}
                    \label{y5_t5}
                    \end{figure}

          \paragraph{Conclusion:} La police et l'épaisseur des lettres n'affectent pas la précision du modèle. Cependant, les lettres colorées et l'arrière-plan des URL affectent la précision du modèle, en plus de cela, une rotation de 90 degrés affecte également la précision. Dans le manuscrit, le modèle échoue totalement à détecter une URL. De plus, le modèle vu détecte également les faux objets contenant des points ou des virgules.
          La solution consiste à incrémenter l'amélioration de l'ensemble de données pour qu'il contienne des exemples plus généralisés qui incluent les problèmes précédents.

\section{Conclusion Géneral}